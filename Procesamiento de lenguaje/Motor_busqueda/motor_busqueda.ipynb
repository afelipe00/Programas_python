{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "from  gensim.parsing.porter import PorterStemmer\n",
    "from gensim import corpora\n",
    "from gensim import models\n",
    "from gensim import similarities\n",
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "from smart_open import open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funcion que retorna una lista con los docs extraidos de los NAF\n",
    "def xml_extract(carpeta):\n",
    "    dicc_documents = {}\n",
    "    for archivo in os.listdir(carpeta):\n",
    "        direc = carpeta + '/' + archivo\n",
    "        doc = ET.parse(direc)\n",
    "        root = doc.getroot()\n",
    "        Ids = root.find('*/public').get(\"publicId\")\n",
    "        raw = root.find('raw').text\n",
    "        dicc_documents[Ids] = raw\n",
    "    return dicc_documents\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funcion que normaliza, quita stopwords y hace steming a los doc\n",
    "def process(text):\n",
    "    p = PorterStemmer()\n",
    "    doc_org = text.lower() #normalizo en minusculas\n",
    "    doc_nor = remove_stopwords(doc_org)\n",
    "    doc_stem = p.stem_sentence(doc_nor)\n",
    "    return doc_stem.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_docs():\n",
    "    dic_docs = {}\n",
    "    dic_query = {}\n",
    "    carpeta = 'C:/Users/Felipe Diaz/Documents/GitHub/Programas_python/Procesamiento de lenguaje/Motor_busqueda/prueba'\n",
    "    dic_docs = xml_extract(carpeta)\n",
    "    carpeta = 'C:/Users/Felipe Diaz/Documents/GitHub/Programas_python/Procesamiento de lenguaje/Motor_busqueda/pquery'\n",
    "    dic_query = xml_extract(carpeta)\n",
    "    #se crea la lista con los documentos procesados\n",
    "    docdict = []\n",
    "    for doc in dic_docs:\n",
    "        docdict.append(process(dic_docs[doc]))\n",
    "    #print(\"\\nveamos\\n\")\n",
    "    #for indice in docdict:\n",
    "    #    print(indice)\n",
    "    #llamamos al metodo gensim para crear el diccionario \n",
    "    #a partir de los documentos\n",
    "    vocabulary_doc = corpora.Dictionary(docdict)\n",
    "    vocabulary_doc.save('dic_documents.dict')\n",
    "    print(vocabulary_doc)\n",
    "    print(vocabulary_doc.token2id)\n",
    "    class mycorpus(object):\n",
    "        def __iter__(self):\n",
    "            for doc in dic_docs:\n",
    "                yield vocabulary_doc.doc2bow(process(dic_docs[doc]))\n",
    "    \n",
    "    corpus_memory_friendly = mycorpus()\n",
    "\n",
    "    corpora.MmCorpus.serialize('corpus.mm',corpus_memory_friendly)\n",
    "\n",
    "    corpus = corpora.MmCorpus('corpus.mm')\n",
    "    print(\"\\ncorpus\\n\",corpus)\n",
    "\n",
    "    #IDF Y TF\n",
    "    vocabulary_doc = corpora.Dictionary.load('dic_documents.dict')\n",
    "    corpus = corpora.MmCorpus('corpus.mm')\n",
    "    tfidf = models.TfidfModel(corpus)\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Dictionary(656 unique tokens: ['1785,', '1812.', '1819.', '1820', '1822.']...)\n{'1785,': 0, '1812.': 1, '1819.': 2, '1820': 3, '1822.': 4, '1833.': 5, '19-year-old': 6, '21,': 7, '6th,': 8, '83.': 9, '[1]': 10, '[2]': 11, 'accid': 12, 'acid': 13, 'activ': 14, 'affect': 15, 'ag': 16, 'alexi': 17, 'also,': 18, 'american': 19, 'armi': 20, 'basi': 21, 'beaumont': 22, 'beaumont:': 23, 'beaumont’': 24, 'best': 25, 'better': 26, 'bit': 27, 'book': 28, 'born': 29, 'born.': 30, 'break': 31, 'broken.': 32, 'caus': 33, 'chemic': 34, 'chemical,': 35, 'children': 36, 'close': 37, 'compani': 38, 'company.': 39, 'complet': 40, 'connecticut': 41, 'consid': 42, 'di': 43, 'did.': 44, 'differ': 45, 'digest': 46, 'digestion.': 47, 'digestion”': 48, 'discov': 49, 'earli': 50, 'emotions,': 51, 'examin': 52, 'exist': 53, 'expect': 54, 'experi': 55, 'famou': 56, 'find': 57, 'fistula.': 58, 'follow': 59, 'food': 60, 'fort': 61, 'french-canadian': 62, 'fur': 63, 'fuse': 64, 'gain': 65, 'gastric': 66, 'gave': 67, 'healed.': 68, 'hole': 69, 'human': 70, 'hydrochlor': 71, 'imag': 72, 'import': 73, 'information,': 74, 'insert': 75, 'insight': 76, 'interest': 77, 'island': 78, 'juic': 79, 'juice,': 80, 'june': 81, 'knowledg': 82, 'known': 83, 'leav': 84, 'lebanon,': 85, 'lectur': 86, 'mackinac': 87, 'main': 88, 'man': 89, 'man,': 90, 'martin': 91, 'martin,': 92, 'martin’': 93, 'mate': 94, 'mechan': 95, 'mere': 96, 'michigan': 97, 'movement.': 98, 'muscl': 99, 'name': 100, 'nature.': 101, 'new': 102, 'notic': 103, 'novemb': 104, 'numer': 105, 'observ': 106, 'open': 107, 'order': 108, 'outliv': 109, 'patient,': 110, 'pepsin.': 111, 'perfor': 112, 'perform': 113, 'period': 114, 'perman': 115, 'physic': 116, 'physician.': 117, 'physiolog': 118, 'physiology”': 119, 'plattsburgh,': 120, 'potential.': 121, 'practic': 122, 'privat': 123, 'process,': 124, 'protect': 125, 'publish': 126, 'pull': 127, 'quickli': 128, 'rang': 129, 'refug': 130, 'rejoin': 131, 'remov': 132, 'research': 133, 'respons': 134, 'rib': 135, 'scientist': 136, 'serv': 137, 'shotgun': 138, 'skin': 139, 'source.': 140, 'st.': 141, 'station': 142, 'stomach': 143, 'stomach,': 144, 'store': 145, 'string': 146, 'suggest': 147, 'surgeon': 148, 'surgeon’': 149, 'surviv': 150, 'system.': 151, 'temperature,': 152, 'then,': 153, 'ti': 154, 'trader': 155, 'uncomfort': 156, 'understand': 157, 'us-american': 158, 'video': 159, 'war': 160, 'went': 161, 'william': 162, 'work': 163, 'wound': 164, 'years.': 165, 'york,': 166, 'young': 167, 'yovisto,': 168, '–': 169, '“experi': 170, '“father': 171, '1858,': 172, '1890.': 173, '1891,': 174, '1897,': 175, '1900.': 176, '1906.': 177, '20': 178, '20,': 179, 'abl': 180, 'academy,': 181, 'accept': 182, 'acclaim': 183, 'accomplish': 184, 'adapt': 185, 'adventur': 186, 'anim': 187, 'animals,': 188, 'animation‘': 189, 'antichrist‘': 190, 'attempt': 191, 'attend': 192, 'author': 193, 'banknote.': 194, 'began': 195, 'belong': 196, 'berl': 197, 'best,': 198, 'birds.': 199, 'bird’': 200, 'boi': 201, 'book‘': 202, 'catch': 203, 'chang': 204, 'children’': 205, 'church': 206, 'colleg': 207, 'competit': 208, 'cover': 209, 'critic': 210, 'danish': 211, 'delight': 212, 'domest': 213, 'elsewhere.': 214, 'enabl': 215, 'excerpt': 216, 'famili': 217, 'family’': 218, 'farm': 219, 'farm.': 220, 'femal': 221, 'film': 222, 'financi': 223, 'first,': 224, 'fly': 225, 'focu': 226, 'free': 227, 'gees': 228, 'genom': 229, 'girls’': 230, 'good.': 231, 'goos': 232, 'goose,': 233, 'group.': 234, 'gösta': 235, 'hold': 236, 'holgersson': 237, 'holgersson,': 238, 'holgersson.': 239, 'however,': 240, 'hurt': 241, 'itali': 242, 'join': 243, 'krona': 244, 'lagerlöf': 245, 'landskrona.': 246, 'last': 247, 'laureat': 248, 'learn': 249, 'let': 250, 'literari': 251, 'literature.': 252, 'long': 253, 'meanwhile,': 254, 'miracl': 255, 'moreover,': 256, 'neck': 257, 'niel': 258, 'nil': 259, 'nils,': 260, 'nils.': 261, 'nils‘.': 262, 'nils’': 263, 'nobel': 264, 'pave': 265, 'pictur': 266, 'plain': 267, 'pleas': 268, 'poetri': 269, 'popular': 270, 'print': 271, 'prize': 272, 'produc': 273, 'produced.': 274, 'receiv': 275, 'refus': 276, 'regular': 277, 'resa': 278, 'revenge.': 279, 'revers': 280, 'royal': 281, 'saga': 282, 'scania,': 283, 'school': 284, 'secondari': 285, 'seek': 286, 'selma': 287, 'seri': 288, 'shrunken': 289, 'size,': 290, 'start': 291, 'stockholm': 292, 'stori': 293, 'success': 294, 'successfulli': 295, 'support': 296, 'sverige‘,': 297, 'sweden': 298, 'sweden,': 299, 'sweden.': 300, 'swedish': 301, 'take': 302, 'talk': 303, 'task': 304, 'teach': 305, 'teacher': 306, 'them.': 307, 'time,': 308, 'tini': 309, 'tomt': 310, 'translat': 311, 'travel': 312, 'turn': 313, 'underbara': 314, 'unnot': 315, 'wai': 316, 'well.': 317, 'white': 318, 'wide': 319, 'wild': 320, 'win': 321, 'wonder': 322, 'work.': 323, 'world': 324, 'write': 325, 'writer': 326, 'writing.': 327, '‘jerusalem‘': 328, '‘nil': 329, '‘pixar': 330, '‘the': 331, '(1805-1894).': 332, '17': 333, '18': 334, '1805': 335, '1805,': 336, '1825': 337, '1827': 338, '1832': 339, '1849': 340, '1854': 341, '1854,': 342, '1856.[2]': 343, '1858.': 344, '1859': 345, '1869': 346, '1869,': 347, '1875,': 348, '1879,': 349, '1888': 350, '1889.': 351, '1894.': 352, '19,': 353, '19th': 354, '25': 355, '7': 356, '74th': 357, '[3]': 358, 'abandon': 359, 'act': 360, 'adopt': 361, 'africa.': 362, 'afterwards,': 363, 'alexandria': 364, 'alexandria.': 365, 'ali': 366, 'ali,': 367, 'allow': 368, 'and,': 369, 'appoint': 370, 'approv': 371, 'april': 372, 'arbitr': 373, 'architect': 374, 'army.': 375, 'articles:': 376, 'assist': 377, 'associ': 378, 'attitud': 379, 'avoid': 380, 'bankrupt': 381, 'baron': 382, 'barthélemi': 383, 'bbc': 384, 'begin': 385, 'behalf': 386, 'bei': 387, 'benjamin': 388, 'berkeley.': 389, 'blow': 390, 'bought': 391, 'bribes.': 392, 'britain.': 393, 'britannica': 394, 'british': 395, 'canal': 396, 'canal,': 397, 'canal.': 398, 'career': 399, 'career-diplomats.': 400, 'celebr': 401, 'centuri': 402, 'chargé': 403, 'charl': 404, 'chose': 405, 'circul': 406, 'colonel.': 407, 'commiss': 408, 'commissari': 409, 'commun': 410, 'compagni': 411, 'companion': 412, 'congress': 413, 'construct': 414, 'consul-gener': 415, 'consular': 416, 'contemporari': 417, 'continu': 418, 'control': 419, 'court': 420, 'cousin,': 421, 'cultur': 422, 'cut': 423, 'deal': 424, 'decemb': 425, 'decis': 426, 'declar': 427, 'depart': 428, 'despit': 429, 'develop': 430, 'dig': 431, 'diplomat': 432, 'direct': 433, 'directli': 434, 'disagr': 435, 'disputes.': 436, 'disraeli,': 437, 'distanc': 438, 'doom': 439, 'dr.': 440, 'drawn': 441, 'du': 442, 'duties.': 443, 'd’affaires.': 444, 'east': 445, 'east.': 446, 'educ': 447, 'effect': 448, 'egypt': 449, 'egypt,': 450, 'egypt.': 451, 'egyptian': 452, 'eiffel': 453, 'elderli': 454, 'emperor': 455, 'emploi': 456, 'empress': 457, 'end': 458, 'engin': 459, 'enter': 460, 'epidem': 461, 'eugenie,': 462, 'european': 463, 'event,': 464, 'expedit': 465, 'explor': 466, 'fail': 467, 'failur': 468, 'fascin': 469, 'father': 470, 'father,': 471, 'father’': 472, 'februari': 473, 'ferdinand': 474, 'fever,': 475, 'final': 476, 'finally,': 477, 'fine': 478, 'fortun': 479, 'french': 480, 'friend': 481, 'futil': 482, 'given': 483, 'good': 484, 'govern': 485, 'government,': 486, 'government.': 487, 'great': 488, 'growth': 489, 'guilti': 490, 'gustav': 491, 'haussmann’': 492, 'heavili': 493, 'held': 494, 'henri': 495, 'histori': 496, 'iii': 497, 'immedi': 498, 'imperi': 499, 'imprisonment.': 500, 'inabl': 501, 'inspir': 502, 'intern': 503, 'ismail': 504, 'italy,': 505, 'iv': 506, 'jail,': 507, 'jean-françoi': 508, 'journalist': 509, 'journei': 510, 'khedive,': 511, 'la': 512, 'land': 513, 'laqueur': 514, 'larg': 515, 'later': 516, 'leader': 517, 'lessep': 518, 'lesseps,': 519, 'lessep‘': 520, 'lessep’': 521, 'level': 522, 'linant': 523, 'liquid': 524, 'lisbon,': 525, 'locks,': 526, 'malaria': 527, 'marie,': 528, 'maritim': 529, 'mathieu': 530, 'medic': 531, 'mediterranean': 532, 'mehemet': 533, 'middl': 534, 'minister,': 535, 'misjudg': 536, 'mismanagement.': 537, 'modified,': 538, 'mougel': 539, 'napoleon': 540, 'napoleon‘': 541, 'niemey': 542, 'occupi': 543, 'office.[1]': 544, 'offici': 545, 'old': 546, 'onlin': 547, 'opposit': 548, 'organ': 549, 'oscar': 550, 'overcom': 551, 'ow': 552, 'paid': 553, 'panama': 554, 'panama.': 555, 'pari': 556, 'paris,': 557, 'paris.': 558, 'pasha': 559, 'pasha.': 560, 'perished.': 561, 'permiss': 562, 'persuad': 563, 'pickax': 564, 'plan': 565, 'polit': 566, 'politician': 567, 'port': 568, 'posit': 569, 'post': 570, 'prevent': 571, 'prime': 572, 'prison.': 573, 'prof.': 574, 'profess': 575, 'project': 576, 'project.': 577, 'provid': 578, 'public': 579, 'pérous': 580, 'read': 581, 'reading:': 582, 'recommend': 583, 'red': 584, 'reduc': 585, 'refer': 586, 'relat': 587, 'renov': 588, 'retir': 589, 'return': 590, 'rout': 591, 'rumor': 592, 'said': 593, 'said.': 594, 'sail': 595, 'scandal,': 596, 'scheme,': 597, 'scienc': 598, 'sea': 599, 'sea,': 600, 'seas,': 601, 'seen': 602, 'sentenc': 603, 'share': 604, 'ship': 605, 'slightli': 606, 'sold': 607, 'son': 608, 'son,': 609, 'soon': 610, 'spain': 611, 'spent': 612, 'stage': 613, 'subsequ': 614, 'substanti': 615, 'suez': 616, 'sultan': 617, 'supervis': 618, 'surveyor': 619, 'survivor': 620, 'this,': 621, 'thoma': 622, 'time': 623, 'tower': 624, 'trade.': 625, 'treat': 626, 'trials,': 627, 'tunisia': 628, 'uncl': 629, 'uncle,': 630, 'undertaking.': 631, 'univers': 632, 'universel': 633, 'us': 634, 'versailles,': 635, 'vice-consul': 636, 'viceroi': 637, 'vicomt': 638, 'visionari': 639, 'visit': 640, 'voyag': 641, 'w.': 642, 'warm': 643, 'welcom': 644, 'west': 645, 'western': 646, 'wish': 647, 'year': 648, 'year,': 649, 'years,': 650, 'yellow': 651, 'yovisto': 652, 'yvelines,': 653, 'zenith”': 654, '“european': 655}\n\ncorpus\n MmCorpus(3 documents, 656 features, 707 non-zero entries)\n"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    load_docs()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}