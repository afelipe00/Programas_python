{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "from  gensim.parsing.porter import PorterStemmer\n",
    "from gensim import corpora\n",
    "from gensim import models\n",
    "from gensim import similarities\n",
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "from smart_open import open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funcion que retorna una lista con los docs extraidos de los NAF\n",
    "def xml_extract(carpeta):\n",
    "    dicc_documents = {}\n",
    "    for archivo in os.listdir(carpeta):\n",
    "        direc = carpeta + '/' + archivo\n",
    "        doc = ET.parse(direc)\n",
    "        root = doc.getroot()\n",
    "        Ids = root.find('*/public').get(\"publicId\")\n",
    "        raw = root.find('raw').text\n",
    "        dicc_documents[Ids] = raw\n",
    "    return dicc_documents\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funcion que normaliza, quita stopwords y hace steming a los doc\n",
    "def process(text):\n",
    "    p = PorterStemmer()\n",
    "    doc_org = text.lower() #normalizo en minusculas\n",
    "    dos_nor = remove_stopwords(doc_org)\n",
    "    doc_stem = p.stem_sentence(doc_nor)\n",
    "    return doc_stem.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "for texto in dicc_documents:\n",
    "    dicc_documents[texto] = remove_stopwords(dicc_documents[texto])\n",
    "    #print(dicc_documents[texto])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_docs():\n",
    "    dic_docs = {}\n",
    "    dic_query = {}\n",
    "    carpeta = 'C:/Users/Felipe Diaz/Documents/GitHub/Programas_python/Procesamiento de lenguaje/Motor_busqueda/prueba'\n",
    "    dic_docs = xml_extract(carpeta)\n",
    "    #for doc in dic_docs:\n",
    "     #   print(doc)\n",
    "    carpeta = 'C:/Users/Felipe Diaz/Documents/GitHub/Programas_python/Procesamiento de lenguaje/Motor_busqueda/pquery'\n",
    "    dic_query = xml_extract(carpeta)\n",
    "    print(\"\\ncambio\\n\")\n",
    "    for doc in dic_query:\n",
    "        print(doc)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "\ncambio\n\nq01\nq02\nq03\nq04\nq06\nq07\nq08\nq09\nq10\n"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    load_docs()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}