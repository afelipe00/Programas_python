{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37332bitc0e1efddd7c742e4bca91aa534a1bda5",
   "display_name": "Python 3.7.3 32-bit"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quitar_stopword(voc,stop):\n",
    "    #print(stop)\n",
    "    temp = {}\n",
    "    for word in voc:\n",
    "        if word not in stop:\n",
    "            temp[word] = voc[word]\n",
    "    #print(len(temp))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "def steamming(voc):\n",
    "    voc['estudio'] = voc.pop('estudiamos')\n",
    "    voc['estudio'] = voc.pop('estudiar')\n",
    "    voc['similitud'] = voc.pop('similitudes')\n",
    "    voc['usa'] = voc.pop('usando')\n",
    "    #voc['modelamiento'] = voc.pop('Modelo')\n",
    "    #voc['modelamiento'] = voc.pop('modelos')\n",
    "    return voc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crea un vocabulario del corpus a partir de una lista de documentos (calcula el IDF)\n",
    "def crear_voc(doc):\n",
    "    voc_corpus = dict()\n",
    "    for indice in doc:\n",
    "        text = indice\n",
    "        text_normal = text.lower()\n",
    "        palabras = re.findall(r'[\\w]+',text_normal)\n",
    "        sin_repetir = set(palabras)\n",
    "        for pal in sin_repetir:\n",
    "            if pal in voc_corpus:\n",
    "                voc_corpus[pal]+=1\n",
    "            else:\n",
    "                voc_corpus[pal]=1\n",
    "    return voc_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizar(doc):\n",
    "    documents = []\n",
    "    for palabras in doc:\n",
    "        text = palabras\n",
    "        text_normal = text.lower()\n",
    "        lista_pal = re.findall(r'[\\w]+',text_normal)\n",
    "        document_words = {}\n",
    "        for key in lista_pal:\n",
    "            if key in document_words:\n",
    "                document_words[key]+=1\n",
    "            else:\n",
    "                document_words[key]=1\n",
    "        documents.append(document_words)\n",
    "    print(\"TF de los documentos:\",documents)\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def term_doc(voc, documentos):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lee archivos de texto metiendolos en listas \n",
    "def lectura_text():\n",
    "    documentos = []\n",
    "    doc_token = []\n",
    "    stop_words = []\n",
    "    voc_corpus = {}\n",
    "    with open(\"corpus.txt\",\"r\",encoding='utf8') as doc:#se leen los documentos\n",
    "        for lineas, texto in enumerate(doc):\n",
    "            documentos.append(texto)\n",
    "    with open(\"stopwords.txt\",\"r\",encoding='utf8') as stop:#se leen las stopwords\n",
    "        for lineas, texto in enumerate(stop):\n",
    "            texto = texto.rstrip('\\n')\n",
    "            stop_words.append(texto)\n",
    "    voc_corpus = crear_voc(documentos)#se crea el vocabularios (en cuantos documentos aparece la palabra)\n",
    "    voc_corpus = steamming(voc_corpus)\n",
    "    voc_corpus = quitar_stopword(voc_corpus,stop_words)\n",
    "    doc_token = tokenizar(documentos)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "TF de los documentos: [{'yo': 1, 'tengo': 1, 'que': 1, 'estudiar': 1, 'para': 1, 'pasar': 1, 'el': 1, 'parcial': 1}, {'si': 1, 'no': 2, 'practico': 1, 'python': 1, 'voy': 1, 'a': 1, 'avanzar': 1, 'en': 1, 'el': 1, 'curso': 1}, {'en': 2, 'clase': 1, 'estudiamos': 1, 'que': 1, 'era': 1, 'un': 1, 'modelo': 1, 'bolsa': 1, 'de': 1, 'palabras': 1}, {'el': 2, 'modelo': 1, 'de': 2, 'bolsa': 1, 'palabras': 1, 'requiere': 1, 'procesar': 1, 'texto': 1}, {'remover': 1, 'stopwords': 1, 'y': 1, 'normalizar': 1, 'son': 1, 'algunas': 1, 'de': 2, 'las': 1, 'tareas': 1, 'procesar': 1, 'el': 1, 'texto': 1}, {'para': 1, 'ponderar': 1, 'la': 1, 'importancias': 1, 'de': 3, 'las': 1, 'palabras': 2, 'en': 1, 'el': 1, 'modelo': 1, 'bolsa': 1, 'se': 1, 'usa': 1, 'tfidf': 1}, {'para': 1, 'calcular': 1, 'similitudes': 1, 'entre': 1, 'documentos': 1, 'debemos': 1, 'vectorizar': 1, 'el': 1, 'modelo': 1, 'de': 2, 'bolsa': 1, 'palabras': 1}, {'usando': 1, 'la': 1, 'distancia': 1, 'coseno': 1, 'podemos': 1, 'calcular': 1, 'las': 1, 'similitudes': 1, 'entre': 1, 'documentos': 1}, {'en': 1, 'python': 1, 'implementamos': 1, 'diferentes': 2, 'medidas': 1, 'de': 2, 'similitud': 1, 'y': 1, 'estudiamos': 1, 'métricas': 1, 'evaluación': 1}, {'entre': 1, 'las': 1, 'métricas': 1, 'más': 1, 'empleadas': 1, 'de': 1, 'evaluación': 1, 'se': 1, 'encuentra': 1, 'la': 1, 'medida': 1, 'f1': 1}]\n"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    lectura_text()"
   ]
  }
 ]
}